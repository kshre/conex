training was done with 20 epochs
found severe overfitting


Changes planned:
* early stopping - epochs set to 10
* dropout for LSTM internally set to 0.2
